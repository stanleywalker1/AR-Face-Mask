{"ast":null,"code":"\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.Pipeline = void 0;\n\nconst zappar_1 = require(\"./zappar\");\n\nconst event_1 = require(\"./event\");\n/**\n * Pipelines manage the flow of data coming in (i.e. the camera frames) through to the output from the different tracking types and computer vision algorithms.\n * @see https://docs.zap.works/universal-ar/javascript/pipelines-and-camera-processing/\n */\n\n\nclass Pipeline {\n  /**\n   * Constructs a new Pipeline.\n  */\n  constructor() {\n    /**\n     * Emitted when the frame is updated.\n    */\n    this.onFrameUpdate = new event_1.Event();\n    /**\n     * @ignore\n    */\n\n    this._onFrameUpdateInternal = new event_1.Event();\n    this._lastFrameNumber = -1;\n    this._z = zappar_1.z();\n    this._impl = this._z.pipeline_create();\n  }\n  /**\n   * Destroys the pipeline.\n   */\n\n\n  destroy() {\n    this._z.pipeline_destroy(this._impl);\n  }\n  /**\n   * Updates the pipeline and trackers to expose tracking data from the most recently processed camera frame.\n   */\n\n\n  frameUpdate() {\n    this._z.pipeline_frame_update(this._impl);\n\n    const frameNumber = this._z.pipeline_frame_number(this._impl);\n\n    if (frameNumber !== this._lastFrameNumber) {\n      this._lastFrameNumber = frameNumber;\n\n      this._onFrameUpdateInternal.emit();\n\n      this.onFrameUpdate.emit();\n    }\n  }\n  /**\n   * @ignore\n  */\n\n\n  _getImpl() {\n    return this._impl;\n  }\n  /**\n   * Sets the WebGL context used for the processing and upload of camera textures.\n   * @param gl - The WebGL context.\n  */\n\n\n  glContextSet(gl) {\n    this._z.pipeline_gl_context_set(this._impl, gl);\n  }\n  /**\n   * Informs the pipeline that the GL context is lost and should not be used.\n  */\n\n\n  glContextLost() {\n    this._z.pipeline_gl_context_lost(this._impl);\n  }\n  /**\n   * Returns the most recent camera frame texture.\n  */\n\n\n  cameraFrameTextureGL() {\n    return this._z.pipeline_camera_frame_texture_gl(this._impl);\n  }\n  /**\n   * Returns a matrix that you can use to transform the UV coordinates of the following full-screen quad in order to render the camera texture:\n   *\n   * Vertex 0: `-1, -1, 0`\n   *\n   * UV 0: `0, 0`\n   *\n   * Vertex 1: `-1, 1, 0`\n   *\n   * UV 1: `0, 1`\n   *\n   * Vertex 2: `1, -1, 0`\n   *\n   * UV 1: `1, 0`\n   *\n   * Vertex 3: `1, 1, 0`\n   *\n   * UV 1: `1, 1`\n   *\n   * @param renderWidth - The width of the canvas.\n   * @param renderHeight - The height of the canvas.\n   * @param mirror - Pass `true` to mirror the camera image in the X-axis.\n   * @returns A 4x4 column-major transformation matrix.\n  */\n\n\n  cameraFrameTextureMatrix(renderWidth, renderHeight, mirror) {\n    return this._z.pipeline_camera_frame_texture_matrix(this._impl, renderWidth, renderHeight, mirror === true);\n  }\n  /**\n  * Draw the camera to the screen as a full screen quad.\n  *\n  * Please note this function modifies some GL state during its operation so you may need to reset the following GL state if you use it:\n  * - The currently bound texture 2D is set to `null` (e.g. `gl.bindTexture(gl.TEXTURE_2D, null)`)\n  * - The currently bound array buffer is set to `null` (e.g. `gl.bindBuffer(gl.ARRAY_BUFFER, null);`)\n  * - The currently bound program is set to `null` (e.g. `gl.useProgram(null)`)\n  * - The currently active texture is set to `gl.TEXTURE0` (e.g. `gl.activeTexture(gl.TEXTURE0)`)\n  * - These features are disabled: `gl.SCISSOR_TEST`, `gl.DEPTH_TEST`, `gl.BLEND`, `gl.CULL_FACE`\n  * @param renderWidth - The width of the canvas.\n  * @param renderHeight - The height of the canvas.\n  * @param mirror - Pass `true` to mirror the camera image in the X-axis.\n  */\n\n\n  cameraFrameDrawGL(renderWidth, renderHeight, mirror) {\n    this._z.pipeline_camera_frame_draw_gl(this._impl, renderWidth, renderHeight, mirror);\n  }\n  /**\n   * Uploads the current camera frame to a WebGL texture.\n  */\n\n\n  cameraFrameUploadGL() {\n    this._z.pipeline_camera_frame_upload_gl(this._impl);\n  }\n  /**\n   * Prepares camera frames for processing.\n   *\n   * Call this function on your pipeline once an animation frame (e.g. during your `requestAnimationFrame` function) in order to process incoming camera frames.\n   *\n   * Please note this function modifies some GL state during its operation so you may need to reset the following GL state if you use it:\n   * - The currently bound framebuffer is set to `null` (e.g. `gl.bindFramebuffer(gl.FRAMEBUFFER, null)`)\n   * - The currently bound texture 2D is set to `null` (e.g. `gl.bindTexture(gl.TEXTURE_2D, null)`)\n   * - The currently bound array buffer is set to `null` (e.g. `gl.bindBuffer(gl.ARRAY_BUFFER, null);`)\n   * - The currently bound element array buffer is set to `null` (e.g. `gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER, null)`)\n   * - The currently bound program is set to `null` (e.g. `gl.useProgram(null)`)\n   * - The currently active texture is set to `gl.TEXTURE0` (e.g. `gl.activeTexture(gl.TEXTURE0)`)\n   * - These features are disabled: `gl.SCISSOR_TEST`, `gl.DEPTH_TEST`, `gl.BLEND`, `gl.CULL_FACE`\n   * - The pixel store flip-Y mode is disabled (e.g. `gl.pixelStorei(gl.UNPACK_FLIP_Y_WEBGL, false)`)\n   * - The viewport is changed (e.g. `gl.viewport(...)`)\n   * - The clear color is changed (e.g. `gl.clearColor(...)`)\n  */\n\n\n  processGL() {\n    this._z.pipeline_process_gl(this._impl);\n  }\n  /**\n   * Returns the camera model (i.e. the intrinsic camera parameters) for the current frame.\n  */\n\n\n  cameraModel() {\n    return this._z.pipeline_camera_model(this._impl);\n  }\n  /**\n   * Returns a transformation where the camera sits, stationary, at the origin of world space, and points down the negative Z axis.\n   *\n   * In this mode, tracked anchors move in world space as the user moves the device or tracked objects in the real world.\n   *\n   * @returns A 4x4 column-major transformation matrix\n  */\n\n\n  cameraPoseDefault() {\n    return this._z.pipeline_camera_pose_default(this._impl);\n  }\n  /**\n   * Returns a transformation where the camera sits at the origin of world space, but rotates as the user rotates the physical device.\n   *\n   * When the Zappar library initializes, the negative Z axis of world space points forward in front of the user.\n   *\n   * In this mode, tracked anchors move in world space as the user moves the device or tracked objects in the real world.\n   *\n   * @param mirror -  Pass `true` to mirror the location in the X-axis.\n   * @returns A 4x4 column-major transformation matrix\n  */\n\n\n  cameraPoseWithAttitude(mirror) {\n    return this._z.pipeline_camera_pose_with_attitude(this._impl, mirror || false);\n  }\n  /**\n   * Returns a transformation with the (camera-relative) origin specified by the supplied parameter.\n   *\n   * This is used with the `poseCameraRelative(...) : Float32Array` functions provided by the various anchor types to allow a given anchor (e.g. a tracked image or face) to be the origin of world space.\n   *\n   * In this case the camera moves and rotates in world space around the anchor at the origin.\n   *\n   * @param o - The origin matrix.\n   * @returns A 4x4 column-major transformation matrix\n  */\n\n\n  cameraPoseWithOrigin(o) {\n    return this._z.pipeline_camera_pose_with_origin(this._impl, o);\n  }\n  /**\n    * Returns true if the current camera frame came from a user-facing camera\n   */\n\n\n  cameraFrameUserFacing() {\n    return this._z.pipeline_camera_frame_user_facing(this._impl);\n  }\n  /**\n    * @ignore\n   */\n\n\n  drawFace(projectionMatrix, cameraMatrix, targetMatrix, m) {\n    this._z.pipeline_draw_face(this._impl, projectionMatrix, cameraMatrix, targetMatrix, m._getImpl());\n  }\n  /**\n    * Returns the number of the current frame.\n   */\n\n\n  frameNumber() {\n    return this._z.pipeline_frame_number(this._impl);\n  }\n\n}\n\nexports.Pipeline = Pipeline;","map":{"version":3,"sources":["/Users/StanleyWalker/Desktop/face-mask-demo/AR-Face-Mask/node_modules/@zappar/zappar/lib/pipeline.js"],"names":["Object","defineProperty","exports","value","Pipeline","zappar_1","require","event_1","constructor","onFrameUpdate","Event","_onFrameUpdateInternal","_lastFrameNumber","_z","z","_impl","pipeline_create","destroy","pipeline_destroy","frameUpdate","pipeline_frame_update","frameNumber","pipeline_frame_number","emit","_getImpl","glContextSet","gl","pipeline_gl_context_set","glContextLost","pipeline_gl_context_lost","cameraFrameTextureGL","pipeline_camera_frame_texture_gl","cameraFrameTextureMatrix","renderWidth","renderHeight","mirror","pipeline_camera_frame_texture_matrix","cameraFrameDrawGL","pipeline_camera_frame_draw_gl","cameraFrameUploadGL","pipeline_camera_frame_upload_gl","processGL","pipeline_process_gl","cameraModel","pipeline_camera_model","cameraPoseDefault","pipeline_camera_pose_default","cameraPoseWithAttitude","pipeline_camera_pose_with_attitude","cameraPoseWithOrigin","o","pipeline_camera_pose_with_origin","cameraFrameUserFacing","pipeline_camera_frame_user_facing","drawFace","projectionMatrix","cameraMatrix","targetMatrix","m","pipeline_draw_face"],"mappings":"AAAA;;AACAA,MAAM,CAACC,cAAP,CAAsBC,OAAtB,EAA+B,YAA/B,EAA6C;AAAEC,EAAAA,KAAK,EAAE;AAAT,CAA7C;AACAD,OAAO,CAACE,QAAR,GAAmB,KAAK,CAAxB;;AACA,MAAMC,QAAQ,GAAGC,OAAO,CAAC,UAAD,CAAxB;;AACA,MAAMC,OAAO,GAAGD,OAAO,CAAC,SAAD,CAAvB;AACA;AACA;AACA;AACA;;;AACA,MAAMF,QAAN,CAAe;AACX;AACJ;AACA;AACII,EAAAA,WAAW,GAAG;AACV;AACR;AACA;AACQ,SAAKC,aAAL,GAAqB,IAAIF,OAAO,CAACG,KAAZ,EAArB;AACA;AACR;AACA;;AACQ,SAAKC,sBAAL,GAA8B,IAAIJ,OAAO,CAACG,KAAZ,EAA9B;AACA,SAAKE,gBAAL,GAAwB,CAAC,CAAzB;AACA,SAAKC,EAAL,GAAUR,QAAQ,CAACS,CAAT,EAAV;AACA,SAAKC,KAAL,GAAa,KAAKF,EAAL,CAAQG,eAAR,EAAb;AACH;AACD;AACJ;AACA;;;AACIC,EAAAA,OAAO,GAAG;AACN,SAAKJ,EAAL,CAAQK,gBAAR,CAAyB,KAAKH,KAA9B;AACH;AACD;AACJ;AACA;;;AACII,EAAAA,WAAW,GAAG;AACV,SAAKN,EAAL,CAAQO,qBAAR,CAA8B,KAAKL,KAAnC;;AACA,UAAMM,WAAW,GAAG,KAAKR,EAAL,CAAQS,qBAAR,CAA8B,KAAKP,KAAnC,CAApB;;AACA,QAAIM,WAAW,KAAK,KAAKT,gBAAzB,EAA2C;AACvC,WAAKA,gBAAL,GAAwBS,WAAxB;;AACA,WAAKV,sBAAL,CAA4BY,IAA5B;;AACA,WAAKd,aAAL,CAAmBc,IAAnB;AACH;AACJ;AACD;AACJ;AACA;;;AACIC,EAAAA,QAAQ,GAAG;AACP,WAAO,KAAKT,KAAZ;AACH;AACD;AACJ;AACA;AACA;;;AACIU,EAAAA,YAAY,CAACC,EAAD,EAAK;AACb,SAAKb,EAAL,CAAQc,uBAAR,CAAgC,KAAKZ,KAArC,EAA4CW,EAA5C;AACH;AACD;AACJ;AACA;;;AACIE,EAAAA,aAAa,GAAG;AACZ,SAAKf,EAAL,CAAQgB,wBAAR,CAAiC,KAAKd,KAAtC;AACH;AACD;AACJ;AACA;;;AACIe,EAAAA,oBAAoB,GAAG;AACnB,WAAO,KAAKjB,EAAL,CAAQkB,gCAAR,CAAyC,KAAKhB,KAA9C,CAAP;AACH;AACD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACIiB,EAAAA,wBAAwB,CAACC,WAAD,EAAcC,YAAd,EAA4BC,MAA5B,EAAoC;AACxD,WAAO,KAAKtB,EAAL,CAAQuB,oCAAR,CAA6C,KAAKrB,KAAlD,EAAyDkB,WAAzD,EAAsEC,YAAtE,EAAoFC,MAAM,KAAK,IAA/F,CAAP;AACH;AACD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACIE,EAAAA,iBAAiB,CAACJ,WAAD,EAAcC,YAAd,EAA4BC,MAA5B,EAAoC;AACjD,SAAKtB,EAAL,CAAQyB,6BAAR,CAAsC,KAAKvB,KAA3C,EAAkDkB,WAAlD,EAA+DC,YAA/D,EAA6EC,MAA7E;AACH;AACD;AACJ;AACA;;;AACII,EAAAA,mBAAmB,GAAG;AAClB,SAAK1B,EAAL,CAAQ2B,+BAAR,CAAwC,KAAKzB,KAA7C;AACH;AACD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACI0B,EAAAA,SAAS,GAAG;AACR,SAAK5B,EAAL,CAAQ6B,mBAAR,CAA4B,KAAK3B,KAAjC;AACH;AACD;AACJ;AACA;;;AACI4B,EAAAA,WAAW,GAAG;AACV,WAAO,KAAK9B,EAAL,CAAQ+B,qBAAR,CAA8B,KAAK7B,KAAnC,CAAP;AACH;AACD;AACJ;AACA;AACA;AACA;AACA;AACA;;;AACI8B,EAAAA,iBAAiB,GAAG;AAChB,WAAO,KAAKhC,EAAL,CAAQiC,4BAAR,CAAqC,KAAK/B,KAA1C,CAAP;AACH;AACD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACIgC,EAAAA,sBAAsB,CAACZ,MAAD,EAAS;AAC3B,WAAO,KAAKtB,EAAL,CAAQmC,kCAAR,CAA2C,KAAKjC,KAAhD,EAAuDoB,MAAM,IAAI,KAAjE,CAAP;AACH;AACD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACIc,EAAAA,oBAAoB,CAACC,CAAD,EAAI;AACpB,WAAO,KAAKrC,EAAL,CAAQsC,gCAAR,CAAyC,KAAKpC,KAA9C,EAAqDmC,CAArD,CAAP;AACH;AACD;AACJ;AACA;;;AACIE,EAAAA,qBAAqB,GAAG;AACpB,WAAO,KAAKvC,EAAL,CAAQwC,iCAAR,CAA0C,KAAKtC,KAA/C,CAAP;AACH;AACD;AACJ;AACA;;;AACIuC,EAAAA,QAAQ,CAACC,gBAAD,EAAmBC,YAAnB,EAAiCC,YAAjC,EAA+CC,CAA/C,EAAkD;AACtD,SAAK7C,EAAL,CAAQ8C,kBAAR,CAA2B,KAAK5C,KAAhC,EAAuCwC,gBAAvC,EAAyDC,YAAzD,EAAuEC,YAAvE,EAAqFC,CAAC,CAAClC,QAAF,EAArF;AACH;AACD;AACJ;AACA;;;AACIH,EAAAA,WAAW,GAAG;AACV,WAAO,KAAKR,EAAL,CAAQS,qBAAR,CAA8B,KAAKP,KAAnC,CAAP;AACH;;AA5LU;;AA8Lfb,OAAO,CAACE,QAAR,GAAmBA,QAAnB","sourcesContent":["\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.Pipeline = void 0;\nconst zappar_1 = require(\"./zappar\");\nconst event_1 = require(\"./event\");\n/**\n * Pipelines manage the flow of data coming in (i.e. the camera frames) through to the output from the different tracking types and computer vision algorithms.\n * @see https://docs.zap.works/universal-ar/javascript/pipelines-and-camera-processing/\n */\nclass Pipeline {\n    /**\n     * Constructs a new Pipeline.\n    */\n    constructor() {\n        /**\n         * Emitted when the frame is updated.\n        */\n        this.onFrameUpdate = new event_1.Event();\n        /**\n         * @ignore\n        */\n        this._onFrameUpdateInternal = new event_1.Event();\n        this._lastFrameNumber = -1;\n        this._z = zappar_1.z();\n        this._impl = this._z.pipeline_create();\n    }\n    /**\n     * Destroys the pipeline.\n     */\n    destroy() {\n        this._z.pipeline_destroy(this._impl);\n    }\n    /**\n     * Updates the pipeline and trackers to expose tracking data from the most recently processed camera frame.\n     */\n    frameUpdate() {\n        this._z.pipeline_frame_update(this._impl);\n        const frameNumber = this._z.pipeline_frame_number(this._impl);\n        if (frameNumber !== this._lastFrameNumber) {\n            this._lastFrameNumber = frameNumber;\n            this._onFrameUpdateInternal.emit();\n            this.onFrameUpdate.emit();\n        }\n    }\n    /**\n     * @ignore\n    */\n    _getImpl() {\n        return this._impl;\n    }\n    /**\n     * Sets the WebGL context used for the processing and upload of camera textures.\n     * @param gl - The WebGL context.\n    */\n    glContextSet(gl) {\n        this._z.pipeline_gl_context_set(this._impl, gl);\n    }\n    /**\n     * Informs the pipeline that the GL context is lost and should not be used.\n    */\n    glContextLost() {\n        this._z.pipeline_gl_context_lost(this._impl);\n    }\n    /**\n     * Returns the most recent camera frame texture.\n    */\n    cameraFrameTextureGL() {\n        return this._z.pipeline_camera_frame_texture_gl(this._impl);\n    }\n    /**\n     * Returns a matrix that you can use to transform the UV coordinates of the following full-screen quad in order to render the camera texture:\n     *\n     * Vertex 0: `-1, -1, 0`\n     *\n     * UV 0: `0, 0`\n     *\n     * Vertex 1: `-1, 1, 0`\n     *\n     * UV 1: `0, 1`\n     *\n     * Vertex 2: `1, -1, 0`\n     *\n     * UV 1: `1, 0`\n     *\n     * Vertex 3: `1, 1, 0`\n     *\n     * UV 1: `1, 1`\n     *\n     * @param renderWidth - The width of the canvas.\n     * @param renderHeight - The height of the canvas.\n     * @param mirror - Pass `true` to mirror the camera image in the X-axis.\n     * @returns A 4x4 column-major transformation matrix.\n    */\n    cameraFrameTextureMatrix(renderWidth, renderHeight, mirror) {\n        return this._z.pipeline_camera_frame_texture_matrix(this._impl, renderWidth, renderHeight, mirror === true);\n    }\n    /**\n    * Draw the camera to the screen as a full screen quad.\n    *\n    * Please note this function modifies some GL state during its operation so you may need to reset the following GL state if you use it:\n    * - The currently bound texture 2D is set to `null` (e.g. `gl.bindTexture(gl.TEXTURE_2D, null)`)\n    * - The currently bound array buffer is set to `null` (e.g. `gl.bindBuffer(gl.ARRAY_BUFFER, null);`)\n    * - The currently bound program is set to `null` (e.g. `gl.useProgram(null)`)\n    * - The currently active texture is set to `gl.TEXTURE0` (e.g. `gl.activeTexture(gl.TEXTURE0)`)\n    * - These features are disabled: `gl.SCISSOR_TEST`, `gl.DEPTH_TEST`, `gl.BLEND`, `gl.CULL_FACE`\n    * @param renderWidth - The width of the canvas.\n    * @param renderHeight - The height of the canvas.\n    * @param mirror - Pass `true` to mirror the camera image in the X-axis.\n   */\n    cameraFrameDrawGL(renderWidth, renderHeight, mirror) {\n        this._z.pipeline_camera_frame_draw_gl(this._impl, renderWidth, renderHeight, mirror);\n    }\n    /**\n     * Uploads the current camera frame to a WebGL texture.\n    */\n    cameraFrameUploadGL() {\n        this._z.pipeline_camera_frame_upload_gl(this._impl);\n    }\n    /**\n     * Prepares camera frames for processing.\n     *\n     * Call this function on your pipeline once an animation frame (e.g. during your `requestAnimationFrame` function) in order to process incoming camera frames.\n     *\n     * Please note this function modifies some GL state during its operation so you may need to reset the following GL state if you use it:\n     * - The currently bound framebuffer is set to `null` (e.g. `gl.bindFramebuffer(gl.FRAMEBUFFER, null)`)\n     * - The currently bound texture 2D is set to `null` (e.g. `gl.bindTexture(gl.TEXTURE_2D, null)`)\n     * - The currently bound array buffer is set to `null` (e.g. `gl.bindBuffer(gl.ARRAY_BUFFER, null);`)\n     * - The currently bound element array buffer is set to `null` (e.g. `gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER, null)`)\n     * - The currently bound program is set to `null` (e.g. `gl.useProgram(null)`)\n     * - The currently active texture is set to `gl.TEXTURE0` (e.g. `gl.activeTexture(gl.TEXTURE0)`)\n     * - These features are disabled: `gl.SCISSOR_TEST`, `gl.DEPTH_TEST`, `gl.BLEND`, `gl.CULL_FACE`\n     * - The pixel store flip-Y mode is disabled (e.g. `gl.pixelStorei(gl.UNPACK_FLIP_Y_WEBGL, false)`)\n     * - The viewport is changed (e.g. `gl.viewport(...)`)\n     * - The clear color is changed (e.g. `gl.clearColor(...)`)\n    */\n    processGL() {\n        this._z.pipeline_process_gl(this._impl);\n    }\n    /**\n     * Returns the camera model (i.e. the intrinsic camera parameters) for the current frame.\n    */\n    cameraModel() {\n        return this._z.pipeline_camera_model(this._impl);\n    }\n    /**\n     * Returns a transformation where the camera sits, stationary, at the origin of world space, and points down the negative Z axis.\n     *\n     * In this mode, tracked anchors move in world space as the user moves the device or tracked objects in the real world.\n     *\n     * @returns A 4x4 column-major transformation matrix\n    */\n    cameraPoseDefault() {\n        return this._z.pipeline_camera_pose_default(this._impl);\n    }\n    /**\n     * Returns a transformation where the camera sits at the origin of world space, but rotates as the user rotates the physical device.\n     *\n     * When the Zappar library initializes, the negative Z axis of world space points forward in front of the user.\n     *\n     * In this mode, tracked anchors move in world space as the user moves the device or tracked objects in the real world.\n     *\n     * @param mirror -  Pass `true` to mirror the location in the X-axis.\n     * @returns A 4x4 column-major transformation matrix\n    */\n    cameraPoseWithAttitude(mirror) {\n        return this._z.pipeline_camera_pose_with_attitude(this._impl, mirror || false);\n    }\n    /**\n     * Returns a transformation with the (camera-relative) origin specified by the supplied parameter.\n     *\n     * This is used with the `poseCameraRelative(...) : Float32Array` functions provided by the various anchor types to allow a given anchor (e.g. a tracked image or face) to be the origin of world space.\n     *\n     * In this case the camera moves and rotates in world space around the anchor at the origin.\n     *\n     * @param o - The origin matrix.\n     * @returns A 4x4 column-major transformation matrix\n    */\n    cameraPoseWithOrigin(o) {\n        return this._z.pipeline_camera_pose_with_origin(this._impl, o);\n    }\n    /**\n      * Returns true if the current camera frame came from a user-facing camera\n     */\n    cameraFrameUserFacing() {\n        return this._z.pipeline_camera_frame_user_facing(this._impl);\n    }\n    /**\n      * @ignore\n     */\n    drawFace(projectionMatrix, cameraMatrix, targetMatrix, m) {\n        this._z.pipeline_draw_face(this._impl, projectionMatrix, cameraMatrix, targetMatrix, m._getImpl());\n    }\n    /**\n      * Returns the number of the current frame.\n     */\n    frameNumber() {\n        return this._z.pipeline_frame_number(this._impl);\n    }\n}\nexports.Pipeline = Pipeline;\n"]},"metadata":{},"sourceType":"script"}